{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2 as cv\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate, concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import datetime\n",
    "from glob import glob\n",
    "\n",
    "class sketch2edge():\n",
    "    def __init__(self):\n",
    "        # dataset\n",
    "        self.sketch = []\n",
    "        self.edge = []\n",
    "        # Input shape\n",
    "        self.img_rows = 128\n",
    "        self.img_cols = 128\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.filters = 64\n",
    "        self.n_batches = 0\n",
    "\n",
    "        # Calculate output shape of D (PatchGAN)\n",
    "        patch = int(self.img_rows / 2**4)\n",
    "        self.disc_patch = (patch, patch, 1)\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.generator()\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.descriminator()\n",
    "        self.discriminator.compile(loss='mse',\n",
    "            optimizer=Adam(0.0002, 0.5),\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Input sketch and their conditioning images(edge)\n",
    "        input_sketch = Input(shape=self.img_shape)\n",
    "        edge = Input(shape=self.img_shape)\n",
    "        fake_sketch = self.generator(input_sketch)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # Discriminators determines validity of translated images / condition pairs\n",
    "        valid = self.discriminator([fake_sketch, input_sketch])\n",
    "\n",
    "        self.combined = Model(inputs=[edge, input_sketch], outputs=[valid, fake_sketch])\n",
    "        self.combined.compile(loss=['mse', 'mae'],\n",
    "                              loss_weights=[1, 100],\n",
    "                              optimizer=Adam(0.0002, 0.5))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def generator(self):\n",
    "        def conv2d(layer_input, filters, f_size=4, bn=True):\n",
    "            \"\"\"Layers used during downsampling\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            return d\n",
    "\n",
    "        def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
    "            \"\"\"Layers used during upsampling\"\"\"\n",
    "            u = UpSampling2D(size=2)(layer_input)\n",
    "            u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n",
    "            if dropout_rate:\n",
    "                u = Dropout(dropout_rate)(u)\n",
    "            u = BatchNormalization(momentum=0.8)(u)\n",
    "            u = Concatenate()([u, skip_input])\n",
    "            return u\n",
    "\n",
    "        # Image input\n",
    "        d0 = Input(shape=self.img_shape)\n",
    "\n",
    "        # Downsampling\n",
    "        d1 = conv2d(d0, self.filters, bn=False)\n",
    "        d2 = conv2d(d1, self.filters*2)\n",
    "        d3 = conv2d(d2, self.filters*4)\n",
    "        d4 = conv2d(d3, self.filters*8)\n",
    "        d5 = conv2d(d4, self.filters*8)\n",
    "        d6 = conv2d(d5, self.filters*8)\n",
    "        d7 = conv2d(d6, self.filters*8)\n",
    "\n",
    "        # Upsampling\n",
    "        u1 = deconv2d(d7, d6, self.filters*8)\n",
    "        u2 = deconv2d(u1, d5, self.filters*8)\n",
    "        u3 = deconv2d(u2, d4, self.filters*8)\n",
    "        u4 = deconv2d(u3, d3, self.filters*4)\n",
    "        u5 = deconv2d(u4, d2, self.filters*2)\n",
    "        u6 = deconv2d(u5, d1, self.filters)\n",
    "\n",
    "        u7 = UpSampling2D(size=2)(u6)\n",
    "        output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u7)\n",
    "\n",
    "        return Model(d0, output_img)\n",
    "\n",
    "        '''        def conv2d(inputs, filters, dropout_rate=0, pool = True):\n",
    "            conv = Conv2D(filters, 4, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "            conv = Conv2D(filters, 4, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv)\n",
    "            if dropout_rate:\n",
    "                drop = Dropout(dropout_rate)(conv)\n",
    "            if dropout_rate:\n",
    "                pool = MaxPooling2D(pool_size=(2, 2))(drop)\n",
    "                return pool\n",
    "            return drop\n",
    "\n",
    "        def deconv2d(input_down, input_up, filters, dropout_rate=0):\n",
    "            up = Conv2D(filters, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(input_up))\n",
    "            merge = concatenate([input_down,up], axis = 3)\n",
    "            conv = Conv2D(filters, 4, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge)\n",
    "            conv = Conv2D(filters, 4, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv)\n",
    "            if dropout_rate:\n",
    "                conv = Dropout(dropout_rate)(conv)\n",
    "            return conv\n",
    "\n",
    "        # input data\n",
    "        input_sketch = Input(shape=self.img_shape)\n",
    "\n",
    "        # downsampling\n",
    "        conv1 = conv2d(input, self.filters)\n",
    "        conv2 = conv2d(conv1, self.filters*2)\n",
    "        conv3 = conv2d(conv2, self.filters*4)\n",
    "        drop4 = conv2d(conv3, self.filters*8, False)\n",
    "        conv4 = conv2d(conv3, self.filters*8)\n",
    "\n",
    "        # middle\n",
    "        conv5 = conv2d(conv4, self.filters*16, 0.5, False)\n",
    "\n",
    "        # upsampling\n",
    "        deconv1 = deconv2d(drop4, conv5, self.filters*8)\n",
    "        deconv2 = deconv2d(conv3, deconv1, self.filters*4)\n",
    "        deconv3 = deconv2d(conv2, deconv2, self.filters*2)\n",
    "        deconv4 = deconv2d(conv1, deconv3, self.filters)\n",
    "\n",
    "        conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(deconv4)\n",
    "        output_img = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "        return Model(input_sketch, output_img)'''\n",
    "\n",
    "\n",
    "    def descriminator(self):\n",
    "        def d_layer(layer_input, filters, f_size=4, bn=True):\n",
    "            \"\"\"Discriminator layer\"\"\"\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            return d\n",
    "\n",
    "        edge = Input(shape=self.img_shape)\n",
    "        input_sketch = Input(shape=self.img_shape)\n",
    "\n",
    "        # Concatenate image and conditioning image by channels to produce input\n",
    "        combined_imgs = Concatenate(axis=-1)([edge, input_sketch])\n",
    "\n",
    "        d1 = d_layer(combined_imgs, self.filters, bn=False)\n",
    "        d2 = d_layer(d1, self.filters*2)\n",
    "        d3 = d_layer(d2, self.filters*4)\n",
    "        d4 = d_layer(d3, self.filters*8)\n",
    "\n",
    "        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n",
    "\n",
    "        return Model([edge, input_sketch], validity)\n",
    "    def load_batch(self, batch_size=1):\n",
    "        data = glob(\"./data/train_data/*\")\n",
    "        label = glob(\"./data/train_label/*\")\n",
    "        self.n_batches = int(len(data) / batch_size)\n",
    "        for i in range(self.n_batches-1):\n",
    "            edge = []\n",
    "            input_sketch = []\n",
    "            for filename in data[i:i+batch_size]:\n",
    "                img = cv.imread(filename, cv.IMREAD_COLOR)/255\n",
    "                img = cv.resize(img, (128, 128))\n",
    "                input_sketch.append(img)\n",
    "            for filename in label[i:i+batch_size]:\n",
    "                img = cv.imread(filename, cv.IMREAD_COLOR)/255\n",
    "                img = cv.resize(img, (128, 128))\n",
    "                edge.append(img)\n",
    "            edge = np.array(edge)\n",
    "            input_sketch = np.array(input_sketch)\n",
    "            yield edge, input_sketch\n",
    "    def train(self, epochs, batch_size=1, sample_interval=50):\n",
    "\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "        # Adversarial loss ground truths\n",
    "        valid = np.ones((batch_size,) + self.disc_patch)\n",
    "        fake = np.zeros((batch_size,) + self.disc_patch)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for batch_i, (edge, input_sketch) in enumerate(self.load_batch(batch_size)):\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "\n",
    "                # Condition on B and generate a translated version\n",
    "                fake_sketch = self.generator.predict(input_sketch)\n",
    "\n",
    "                # Train the discriminators (original images = real / generated = Fake)\n",
    "                d_loss_real = self.discriminator.train_on_batch([edge, input_sketch], valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch([fake_sketch, input_sketch], fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "                # -----------------\n",
    "                #  Train Generator\n",
    "                # -----------------\n",
    "\n",
    "                # Train the generators\n",
    "                g_loss = self.combined.train_on_batch([edge, input_sketch], [valid, edge])\n",
    "\n",
    "                elapsed_time = datetime.datetime.now() - start_time\n",
    "                # Plot the progress\n",
    "                print (\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %f] time: %s\" % (epoch, epochs,\n",
    "                                                                        batch_i, self.n_batches,\n",
    "                                                                        d_loss[0], 100*d_loss[1],\n",
    "                                                                        g_loss[0],\n",
    "                                                                        elapsed_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strat\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "    session = tf.Session(config=config)\n",
    "    print (\"strat\")\n",
    "    gan = sketch2edge()\n",
    "    gan.train(epochs=200, batch_size=1, sample_interval=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
